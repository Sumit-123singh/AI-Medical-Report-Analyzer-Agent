ğŸ¥ AI Medical Report Analyzer

Backend & AI System using FastAPI, OCR, and Multi-Agent LLM Architecture

AI Medical Report Analyzer is a backend-focused, production-style AI system designed to help both doctors and patients understand medical reports easily.
It processes medical reports (PDF/images), extracts text using OCR, analyzes the content using AI agents, explains results based on user role, supports multiple Indian languages, and generates audio output.

âš ï¸ This project intentionally focuses on backend engineering, AI system design, and real-world workflows. Frontend is minimal and Swagger UI is used for interaction.

ğŸ¯ Problem Statement

Medical reports are often:

Difficult for patients to understand

Time-consuming for doctors to interpret and explain

This system bridges that gap by:

Providing doctor-level technical insights

Providing patient-friendly explanations

Supporting regional languages

Offering audio explanations for accessibility

ğŸ§‘â€âš•ï¸ Two Explanation Modes (Core Feature)
ğŸ”¹ Doctor Mode

Technical and clinical explanation

Uses medical terminology

Helps doctors quickly review reports

Suitable for professional understanding

ğŸ”¹ Patient Mode

Simple, easy-to-understand language

Explains medical terms step-by-step

Designed for non-technical users

Improves patient awareness and clarity

ğŸ‘‰ The same report is processed differently based on the selected mode.

ğŸŒ Multilingual Support

Supported languages:

âœ… English

âœ… Hindi

âœ… Marathi

âœ… Tamil

This improves accessibility in Indian healthcare environments.
The translation logic is modular and can be extended easily.

ğŸš€ Key Features

ğŸ” OAuth2 + JWT authentication

ğŸ“„ Upload medical reports (PDF / Image)

ğŸ§  Multi-Agent AI architecture

ğŸ§‘â€âš•ï¸ Doctor & Patient explanation modes

ğŸŒ Multilingual medical explanations

ğŸ”Š Text-to-Speech audio generation

ğŸ—‚ï¸ User-specific report history

âš™ï¸ Background task processing

ğŸ§± Clean, modular FastAPI architecture

ğŸ§  High-Level System Flow
Medical Report (PDF / Image)
        â†“
OCR Extraction
        â†“
Text Cleaning
        â†“
Medical Understanding Agent
        â†“
Mode Selection (Doctor / Patient)
        â†“
Explanation Agent
        â†“
Translation Agent
        â†“
Text-to-Speech Agent
        â†“
Database Storage + Audio File

ğŸ“„ OCR (Optical Character Recognition)
Why OCR?

Medical reports are often scanned PDFs or images.
AI models cannot directly read images â€” OCR converts them into text.

OCR Tools Used

pytesseract â†’ Text extraction

Pillow (PIL) â†’ Image preprocessing

PDF reader â†’ PDF text extraction

OpenCV (experiments) â†’ Improve OCR accuracy

OCR Pipeline

Detect file type (PDF/Image)

Convert pages to images if needed

Extract raw text

Clean noisy OCR output

Pass clean text to AI agents

ğŸ§  AI Architecture (Multi-Agent Design)

Each AI agent has one responsibility:

Medical Agent â†’ Understands medical content

Explanation Agent â†’ Simplifies medical language

Translation Agent â†’ Converts language

Voice Agent â†’ Generates audio output

This follows Single Responsibility Principle and keeps the system modular.

ğŸ§© Service Layer (Important Design Choice)

AI logic is separated from API routes using a service layer.

Services:

llm_service.py â†’ Central LLM interface

report_processor.py â†’ End-to-end report pipeline

service_processor.py â†’ Coordinates agents

translation_service.py â†’ Language handling

tts_service.py â†’ Audio generation

ğŸ‘‰ This makes the system scalable, testable, and clean.

ğŸ¦™ Ollama Server & LLaMA 3.2
What is Ollama?

Ollama is a local LLM server that runs large language models offline.

Why Ollama?

No paid API dependency

Full data privacy (important for medical data)

Faster local experimentation

Model Used

LLaMA 3.2 (latest)

Use Cases

Medical understanding

Explanation generation

Summarization

Translation prompts

ğŸ”Š Text-to-Speech (Audio Generation)

Uses gTTS (Google Text-to-Speech)

Converts final explanation into audio

Audio files stored per report

Helpful for:

Visually impaired users

Elderly patients

Audio-based understanding

Audio files are stored in the audio/ directory.

âš™ï¸ Background Tasks (FastAPI)

Heavy operations like:

OCR

AI inference

Translation

Audio generation

are executed using FastAPI BackgroundTasks.

Benefits:

Faster API response

Non-blocking execution

Better scalability

Improved user experience

ğŸ“ Complete Project Structure

****ai-medical-report-agent/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ main.py
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ security.py
â”‚   â”‚   â””â”€â”€ deps.py
â”‚   â”‚
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ session.py
â”‚   â”‚   â””â”€â”€ init_db.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ report.py
â”‚   â”‚   â””â”€â”€ analysis.py
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â””â”€â”€ report.py
â”‚   â”‚
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ jwt.py
â”‚   â”‚   â”œâ”€â”€ hashing.py
â”‚   â”‚   â””â”€â”€ routes.py
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ medical_agent.py
â”‚   â”‚   â”œâ”€â”€ explain_agent.py
â”‚   â”‚   â”œâ”€â”€ translate_agent.py
â”‚   â”‚   â””â”€â”€ voice_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_service.py
â”‚   â”‚   â”œâ”€â”€ report_processor.py
â”‚   â”‚   â”œâ”€â”€ service_processor.py
â”‚   â”‚   â”œâ”€â”€ translation_service.py
â”‚   â”‚   â””â”€â”€ tts_service.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ocr/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pdf_reader.py
â”‚   â”‚   â”œâ”€â”€ image_reader.py
â”‚   â”‚   â””â”€â”€ clean_text.py
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ report_routes.py
â”‚   â”‚   â””â”€â”€ history_routes.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ file_utils.py
â”‚   â”‚   â””â”€â”€ response_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ test_agent_run.py
â”‚   â”œâ”€â”€ test_cv2.py
â”‚   â””â”€â”€ test_ocr.py
â”‚
â”œâ”€â”€ uploads/
â”œâ”€â”€ audio/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
****

1ï¸âƒ£ Clone the Repository

Open your terminal and run:

git clone https://github.com/<your-username>/ai-medical-report-agent.git


Move into the project folder:

cd ai-medical-report-agent

2ï¸âƒ£ Create a Virtual Environment (Recommended)
On Windows
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install Project Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Install System Dependencies (Important)
ğŸ§¾ Tesseract OCR (Required)
Windows

Download from:
https://github.com/UB-Mannheim/tesseract/wiki

Install and note the path (example):

C:\Program Files\Tesseract-OCR\tesseract.exe


Add it to System PATH

ğŸ§  Ollama (LLM Server)

Download Ollama from:
https://ollama.com/download

Install and start Ollama

Pull the model:

ollama pull llama3.2


Verify Ollama is running:

ollama list

5ï¸âƒ£ Create .env File

In the project root, create a .env file:

DATABASE_URL=sqlite:///./medical.db
SECRET_KEY=your_secret_key
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60

6ï¸âƒ£ Initialize the Database

If required:

python app/db/init_db.py


This creates database tables.

7ï¸âƒ£ Start the FastAPI Server
uvicorn app.main:app --reload


Server runs at:

http://127.0.0.1:8000

8ï¸âƒ£ Open Swagger UI (Main Interface)

Open your browser:

http://127.0.0.1:8000/docs


## ğŸ‘¤ Author

**Sumit Singh**  
Backend & AI Engineer  

Passionate about building scalable backend systems and AI-powered applications using FastAPI, OCR pipelines, LLMs, and clean architecture principles.
